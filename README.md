# Deep_Learning_2023_final_project_detector

Продвинутый поток. Тема детекция. Трек  Продуктовый.
Stepic  ID: 592652899

Использование модели предобученой модели  YOLO V8 для детекции человека , с использованием стереокамеры для получения растояния до него.

Используеться репозоторий https://github.com/ultralytics/ultralytics


Обычно в стереокамерах расчитывают карту несоответствия ,  по которой потом расчитываеться глубина или облако точек


![disparity_map](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/8fa0c25f-c5c6-4d94-8bbe-1b38bf03e66f)

Но проблема данного метода в высоких вычилительных затратах, для качественной карты карты диспарности алгоритмы проводят префильтрацию и сами алгоритмы вычислительно затратны , это решаеться использованием реализаций на cuda , но всеравно этого не хватает особенно при высоких разрешениях входных фотографий(большое разрешение необходимо для увеличения максимальной дистанции которую можно расчитвть). И включая вычислительную нагрузку самого детектора , работа в реальном времени затруднительна.
Поэтому решение: использвоание самих boundingbox из модели детекции для расчета несоответствия,
это значительно ускоряет процесс расчета растояния до объекта.  

Основная задумка для demo версии: детекция человека на двух снимках левой и правой камеры, расчет несоответсвия меджду центрами двух bouding box, зная характеристики стереокамеры можно расчитать
несоответствие(disparity) и из него  растояние до объекта.
По формуле, https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html




![stereo_depth](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/a5f6a10a-58fc-47fb-afea-fe1cb7a480fe)

![image](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/cfb3d866-2e2c-4d26-a099-434bb87dbe55)


![image](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/e7f6a795-a2e0-4b7a-b5c0-bab353cebaf3)

Преимущество данного решения ,в высокой производительности. 

Демоверсия реализована с использованием телеграмм бота и библиотеки telebot.
Отправляешь видео или фото, получаешь обработтаный результат. Для проверки работоспособности я отдельно пришлю  демонстрациооное видео  с камеры , и фотографии

Для демонстрации использована стереокамера Zed. Известны ее характеристики , и есть калиброваочные данные для стереоисправления.


![photo_2023-07-05_14-00-46](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/5757b442-20d4-4f34-8d45-6aa244648641)


Пример работы 

![демо](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/1608e815-8365-4da3-8305-deca8fc671e4)

В рамке показан класс и расчитанное растояние до объекта
,также в верхнем левом углу показана среднаяя частота  кадров с которой проходила обработка обработка
В данном случае модель запускалась на видеокарте gtx 1080ti 

ПРОБЛЕМЫ 

Сложность сопоставления можества объектов одного класса, нужно определиить какой объект на правом изоображении соответсвует левому , так же могут происходить  ложные срабатывания  где на левом изображении объект не найден а на правом найдени (это испаравляется повышением порога достоверности в детеектирующей модели.
Так же возникают ошибки когда часть объекта выходит за поле зрения камеры b , и бывают выбросы по предпологаемому растоянию связанные с срабатывением детекции модели 

Потенциальные решения 

Были произведены попытки сопоставления ограничевающих рамок методами отслеживания объектов методами opencv

![image](https://github.com/wvw321/Deep_Learning_2023_final_project_detector/assets/62586788/6d066b90-f2a9-4b8d-a198-7ba88b360b02)

наилучшие резуьтаты дал метод TrackerNano , но проблема в том что это реализация на cpu и уступает по скоросте самой модели yolov8 на gpu.

далее был найден репозиторий https://github.com/mikel-brostrom/yolo_tracking

И это потенциальное решение качественного сопоставления как в задаче трекинга, но возможно это излишне вычислительно затратно

Есть вариант написание собственного алгоритма сопастовления ограничивающих рамок, в теории просто нужно искать наиближайшую рамку слева.
но могут возникать условия что на одном кадре объкет детектируеться а на другом нет. Много подводных камней.



